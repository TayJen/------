{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from time import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(data.drop('is_fake', axis=1), data['is_fake'],\n",
    "                                                          test_size=0.15, random_state=13)\n",
    "\n",
    "    t0 = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time()\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    t2 = time()\n",
    "\n",
    "    time_train = t1 - t0\n",
    "    time_pred_valid = t2 - t1\n",
    "\n",
    "    print(model)\n",
    "    print(f'Training time: {time_train}')\n",
    "    print(f'Prediction time (validation): {time_pred_valid}')\n",
    "    print('Accuracy score train set :', model.score(X_train, y_train))\n",
    "    print('Accuracy score valid set  :', accuracy_score(y_valid, y_pred_valid))\n",
    "    print('Validation classification report: ')\n",
    "    print(classification_report(y_valid, y_pred_valid))\n",
    "    print('Test classification report: ')\n",
    "    \n",
    "    print('\\n -------------------------------------------------------------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'new data\\\\'\n",
    "name_train = 'new_df_train.csv'\n",
    "\n",
    "df = pd.read_csv(path + name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "Training time: 3.436037063598633\n",
      "Prediction time (validation): 0.05784320831298828\n",
      "Accuracy score train set : 0.9836534532080098\n",
      "Accuracy score valid set  : 0.8368055555555556\n",
      "Validation classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       435\n",
      "           1       0.89      0.77      0.82       429\n",
      "\n",
      "    accuracy                           0.84       864\n",
      "   macro avg       0.84      0.84      0.84       864\n",
      "weighted avg       0.84      0.84      0.84       864\n",
      "\n",
      "Test classification report: \n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for model in [LogisticRegression(), KNeighborsClassifier(),\n",
    "#               RandomForestClassifier(), XGBClassifier()]:\n",
    "train_model(df, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training time: 0.21146583557128906\n",
      "Prediction time (validation): 1.0922200679779053\n",
      "Accuracy score train set : 0.8475684511646915\n",
      "Accuracy score valid set  : 0.6481481481481481\n",
      "Validation classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67       435\n",
      "           1       0.66      0.59      0.62       429\n",
      "\n",
      "    accuracy                           0.65       864\n",
      "   macro avg       0.65      0.65      0.65       864\n",
      "weighted avg       0.65      0.65      0.65       864\n",
      "\n",
      "Test classification report: \n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(df, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Training time: 30.289986610412598\n",
      "Prediction time (validation): 0.1655571460723877\n",
      "Accuracy score train set : 1.0\n",
      "Accuracy score valid set  : 0.7743055555555556\n",
      "Validation classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       435\n",
      "           1       0.88      0.63      0.74       429\n",
      "\n",
      "    accuracy                           0.77       864\n",
      "   macro avg       0.80      0.77      0.77       864\n",
      "weighted avg       0.80      0.77      0.77       864\n",
      "\n",
      "Test classification report: \n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(df, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python Interpreter\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:55:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Training time: 60.81608533859253\n",
      "Prediction time (validation): 0.23636651039123535\n",
      "Accuracy score train set : 0.8220269718022067\n",
      "Accuracy score valid set  : 0.7511574074074074\n",
      "Validation classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.78       435\n",
      "           1       0.84      0.61      0.71       429\n",
      "\n",
      "    accuracy                           0.75       864\n",
      "   macro avg       0.77      0.75      0.75       864\n",
      "weighted avg       0.77      0.75      0.75       864\n",
      "\n",
      "Test classification report: \n",
      "\n",
      " -------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(df, XGBClassifier())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2f5a8c3b1f2eab5da0c6d300150fde14b5af910044bc98130fc437c147598ff"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
